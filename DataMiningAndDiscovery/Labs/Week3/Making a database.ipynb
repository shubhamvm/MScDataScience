{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5019de54-eee4-4946-bca6-50cb71b98742",
   "metadata": {},
   "source": [
    "# Creating a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de65563-181e-4979-acdb-41e15152118d",
   "metadata": {},
   "source": [
    "Here you will be creating the data that will go into your database. The data is created in python and will be turned into a database in SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a847fdab-ef0e-4816-81d6-2fc92fec6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f079fd-42ed-47b0-bdff-8bb2aedc42ca",
   "metadata": {},
   "source": [
    "We need to create data of various formats: nominal, ordinal, interval and ratio.\n",
    "Let's pick the topic of house sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f0f978-089b-4928-adc9-57a0c640eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Postcode Age_Group Construction_Date  House_Price\n",
      "0     AL07     46-55        1893-07-22       231165\n",
      "1     AL01     26-35        1962-04-27       618135\n",
      "2     AL01     26-35        1738-06-15       726213\n",
      "3     AL03     46-55        1945-08-13       576944\n",
      "4     AL04     36-45        1980-10-18       485213\n"
     ]
    }
   ],
   "source": [
    "# Number of samples\n",
    "n = 1000\n",
    "\n",
    "# Nominal data: postcodes. Note that these are made less specific for data privacy reasons.\n",
    "postcodes = [f'AL{str(i).zfill(2)}' for i in range(1, 11)]\n",
    "postcode_data = np.random.choice(postcodes, n)\n",
    "\n",
    "# Ordinal data: Age groups\n",
    "age_groups = ['18-25', '26-35', '36-45', '46-55', '56-65', '66+']\n",
    "age_group_data = np.random.choice(age_groups, n, p=[0.1, 0.2, 0.3, 0.2, 0.1, 0.1])\n",
    "\n",
    "# Interval data: Age of construction\n",
    "construction_year = np.random.randint(1700, 2000, n)\n",
    "construction_month = np.random.randint(1, 13, n)\n",
    "construction_day = np.random.randint(1, 29, n)\n",
    "construction_date = [f'{construction_year[i]}-{str(construction_month[i]).zfill(2)}-'\n",
    "                     f'{str(construction_day[i]).zfill(2)}' for i in range(n)]\n",
    "\n",
    "# Ratio data: Price of the house\n",
    "price_data = np.random.lognormal(mean=13, sigma=0.5, size=n).astype(int)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Postcode': postcode_data,\n",
    "    'Age_Group': age_group_data,\n",
    "    'Construction_Date': construction_date,\n",
    "    'House_Price': price_data\n",
    "})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94999c1-d9a2-4a8c-ac3c-d02061be742f",
   "metadata": {},
   "source": [
    "That's a minimal example, now create some additional (at least 4 more) columns for any the following concepts:\n",
    "- Number of Bedrooms\n",
    "- Number of Bathrooms\n",
    "- Total Square Footage\n",
    "- Property Type (Detached, Semi-Detached, etc.)\n",
    "- Number of Floors\n",
    "- Furnishing (Finished, Unfinished)\n",
    "- Garden Size\n",
    "- Time on Market\n",
    "- Mortgage Rate\n",
    "- Number of Previous Owners\n",
    "- Pet-Friendly (Yes/No)\n",
    "- Appliances Included\n",
    "- Internet Connectivity (Fiber, DSL, etc.)\n",
    "- Local Crime Rate\n",
    "- Distance to Nearby Schools\n",
    "- Distance to Motorway\n",
    "- Name of Seller\n",
    "\n",
    "\n",
    "Random is better and make sure to ensure the numbers **make sense** and have a consistent N.\n",
    "Read the numpy random documentation for ideas on different distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835140f7-2da0-4f5f-a149-d20822b2cf4c",
   "metadata": {},
   "source": [
    "Most real databases have missing data or otherwise undesirable values, \"filler\" values. You can simulate this with masking. Note that integers cannot have NaNs as options (so not np.random.randint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d15e6e02-71ee-4b86-87be-ccb51205dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "square_footage = np.random.uniform(50, 1000, n)\n",
    "\n",
    "# Randomly select 50 indices to set to NaN\n",
    "n_points = 50\n",
    "random_indices = np.random.choice(square_footage.size, n_points, replace=False).astype(int)\n",
    "square_footage[random_indices] = np.nan\n",
    "print(len(square_footage[np.isnan(square_footage)]))  # check how many values are NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38967981-01a4-438d-9673-1f79c73c691a",
   "metadata": {},
   "source": [
    "You should apply something similar to your created data. Also of use if you want to mask out given values (rather than randomly selecting indices), is to use np.where(condition, thing to do if true, thing to do if false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f5330d-a509-453e-abca-97ff61ab4847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258bd54-eca6-49bc-a3a1-50d1eb547050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83dc029a-730d-4825-91a4-843a2bb2fc8b",
   "metadata": {},
   "source": [
    "It is helpful to set as your dataframe index, the primary key of the database, as this is by default saved to the output csv. Note that this can be a compound key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71122d05-ff7a-4c66-856f-50426a524e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example index\n",
    "df.set_index(['Postcode', 'seller_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f51d2-66d3-426b-b134-6e5a2b93568c",
   "metadata": {},
   "source": [
    "Okay, now for splitting a pandas dataframe into multiple csvs, we need to select different columns at once.\n",
    "To do so, pass a list of column names to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef153302-5787-425e-9ea5-8dcb1e04ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information on Seller relation\n",
    "df_seller_information = df[['seller_name', 'number_previous_owners', 'time_on_market']]\n",
    "df_seller_information.to_csv('house_seller.csv')  # by default, the index is saved to the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c30ccf-4119-4a93-b9f0-00e3c0565aa5",
   "metadata": {},
   "source": [
    "The tables to be saved depend upon what columns you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe27b9-748d-4aa8-a098-adbe59bf8857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661f3cfc-3d62-4eb2-aa04-986e5265201b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outputting csvs to SQLite\n",
    "- Open SQLite Browser\n",
    "- New database, save as house_database.db\n",
    "- Ensure you are on the database structure tab\n",
    "- File > Import > Table from CSV file\n",
    "- Check the preview looks as expected then confirm the import\n",
    "- Write changes (if you skip this, it will prompt you on the next step)\n",
    "- Right click on the new table then modify table\n",
    "- Check the boxes as appropriate, Primary Key, Not Null, Auto Increment, Unique\n",
    "- On some tables, scroll along to the right and click on the foreign key section, and assign the relation/attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa631696-a984-497b-ba66-c15acf56b98b",
   "metadata": {},
   "source": [
    "Once all of this is complete, perform any JOIN transaction under the Execute SQL tab.\n",
    "From that join, use the SQLite plotting functionality to make a basic scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9483db3-0c22-4cfd-8e5b-6d1a8e605532",
   "metadata": {},
   "source": [
    "Upload the image from your scatter plot (there is a button to save the image) to this notebook below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70ade3-6d70-4d3c-90f5-d5c49ae4bf6d",
   "metadata": {},
   "source": [
    "![title](yourimage.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
